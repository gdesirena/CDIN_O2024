{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e07ecae",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='../Imagenes/iteso.jpg' width=\"50\" height=\"100\"/></a>\n",
    "\n",
    "# <center> <font color= #000047> Módulo III: Aprendizaje supervizado: Máquinas de Vector Soporte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bde77",
   "metadata": {},
   "source": [
    "Generalmente, `Support Vector Machines` se considera un algoritmo de aprendizaje supervizado para clasificación, pero puede emplearse en ambos tipos de problemas de clasificación y regresión. \n",
    "\n",
    ">Puede manejar fácilmente múltiples variables continuas y categóricas.\n",
    "\n",
    ">SVM construye un hiperplano en un espacio multidimensional para separar diferentes clases.\n",
    "\n",
    ">SVM genera un hiperplano óptimo de manera iterativa, que se utiliza para minimizar un error. La idea central de SVM es encontrar un hiperplano marginal máximo (MMH) que divida mejor el conjunto de datos en clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76c93de",
   "metadata": {},
   "source": [
    "> **Vectores Soportes:** Los vectores de soporte son los puntos de datos más cercanos al hiperplano. Estos puntos definirán mejor la línea de separación calculando los márgenes. Estos puntos son más relevantes para la construcción del clasificador.\n",
    "\n",
    "> **Hiperplano:** Un hiperplano es un plano de decisión que separa un conjunto de objetos que tienen diferentes membresías de clase.\n",
    "\n",
    ">**Margen:** Un margen es un espacio que existe entre dos líneas obtenidas en función de los puntos de cada clase. Esto se calcula como la distancia perpendicular desde la línea hasta los vectores soporte o los puntos más cercanos. Si el margen es mayor entre las clases, entonces se considera un buen margen, un margen más pequeño es un mal margen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa21fd2",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "El objetivo principal es segregar el conjunto de datos dado de la mejor manera posible. La distancia entre los puntos más cercanos se conoce como margen. El objetivo es seleccionar un hiperplano con el máximo margen posible entre los vectores de soporte en el conjunto de datos dado. SVM busca el hiperplano marginal máximo.\n",
    "\n",
    "1. Basada en kernels que realiza clasificación lineal sobre vectores transformados a un espacio de dimensión superior, es decir, separa mediante un hiperplano en el espacio transformado.\n",
    "\n",
    "2. Encuentra el hiperplano que maximiza el “margen” entre dos clases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae61e6",
   "metadata": {},
   "source": [
    "El objetivo de este algoritmo es encontrar un hiperplano un un espacio N-dimensional (N = número de variables) que clasifica datos\n",
    "\n",
    "Se busca encontrar un hiperplano que tenga el margen máximo (máxima distancia) entre los puntos de ambas clases. \n",
    "\n",
    "<img style=\"float: center; margin: 15px 15px 0px 0px;\" src=\"https://miro.medium.com/max/600/0*9jEWNXTAao7phK-5.png\" width=\"250px\" height=\"80px\" />\n",
    "\n",
    "<img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://miro.medium.com/max/600/0*0o8xIA4k3gXUDCFU.png\" width=\"250px\" height=\"80px\" />\n",
    "\n",
    "\n",
    "\n",
    "**Se necesita optimizar la siguiente función de costo**\n",
    "\n",
    "$$\n",
    "\\min _{\\mathbf{w}, b}\\|\\mathbf{w}\\|^{2}+C \\sum_{i=1}^{n} \\xi_{i}^{p} \\text { under constraints } y_{i}\\left(\\mathbf{w} \\cdot \\mathbf{x}_{i}+b\\right) \\geq 1-\\xi_{i}, \\quad \\xi_{i} \\geq 0\n",
    "$$\n",
    "\n",
    "\n",
    "**El truco del Kernel**\n",
    "\n",
    "No todos los datos son linealmente separables, casi todos los datos están aleatoriamente distribuidos, lo cual hace difícil separar linealmente los datos. \n",
    "\n",
    "<img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://miro.medium.com/max/838/1*gXvhD4IomaC9Jb37tzDUVg.png\" width=\"450px\" height=\"280px\" />\n",
    "\n",
    "En escencia, lo que hace el truco del kernel es ofrecer una manera más eficiente y menos costosa de aumentar la dimensionalidad de los datos. \n",
    "\n",
    "**Algunos tipos de kernel**\n",
    "- Lineal\n",
    "$$K(x,x*)=x \\cdot x^{*}$$\n",
    "- Polinomial \n",
    "$$K(x,x*)=(x \\cdot x^{*} +1)^{d}$$\n",
    "- Gaussian Radial Basis \n",
    "$$K(x,x*)=\\exp^{-\\frac{\\|x-x^{*}\\|^{2}}{2\\sigma^{2}}}=\\exp^{-\\gamma\\|x-x^{*}\\|^{2}} $$\n",
    "\n",
    "**Se deben cumplir varias cosas para obtener el resultado óptimo:**\n",
    "\n",
    "- Este algoritmo funciona muy bien si se tienen los datos limpios. Si los datos están muy dispersos no se podrá crear una fórmula adecuada. Se recomienda estandarizar los datos previamente. \n",
    "- No es adecuado para conjuntos de datos grandes. Lleva mucho tiempo el entrenamiento\n",
    "- Menos efectivo en conjuntos de datos con columnas superpuestas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513cd4e",
   "metadata": {},
   "source": [
    "La linea que maximiza ese margen es la que se escoge como el modelo óptimo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e7963",
   "metadata": {},
   "source": [
    "## Ejemplo 1: Datos Linealmente separables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dee855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Librerías\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375f14d",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Tratar con datos que no son linealmente separables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82c931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar los datos \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea55677",
   "metadata": {},
   "source": [
    "Algunos problemas no se pueden resolver utilizando un hiperplano lineal.\n",
    "\n",
    ">En tal situación, **SVM** usa un truco del kernel para transformar el espacio de entrada en un espacio dimensional más grande. \n",
    "\n",
    "**SVM Kernels**\n",
    "\n",
    "El algoritmo SVM se implementa en la práctica utilizando un kernel. \n",
    "\n",
    ">Un **kernel** transforma un espacio de datos de entrada en la forma requerida. Aquí, el kernel toma un espacio de entrada de menor dimensión y lo transforma en un espacio de mayor dimensión. En otras palabras, se puede decir que se convierte un problema no linealmente separable en problemas separables al agregarle una mayor dimensión. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9510e1",
   "metadata": {},
   "source": [
    "**Kernel lineal** Se puede utilizar un kernel lineal como producto escalar normal cualesquiera dos observaciones dadas. El producto entre dos vectores es la suma de la multiplicación de cada par de valores de entrada.\n",
    "\n",
    "$$K(x,x_i) = \\sum(x*x_i) $$\n",
    "\n",
    "\n",
    "**Kernel polinomial** Un kernel polinomial es una forma más generalizada del kernel lineal. El kernel polinomial puede distinguir el espacio de entrada curvo o no lineal.\n",
    "\n",
    "$$K(x,x_i) = 1 \\sum(x*x_i)^d $$\n",
    "\n",
    "Donde $d$ es el grado del polinomio. $d = 1$ es similar a la transformación lineal. \n",
    "\n",
    "**Kernel de función de base radial (RBF)** RBF puede mapear un espacio de entrada en un espacio dimensional infinito.\n",
    "\n",
    "$$K(x,x_i) = exp(-\\gamma * \\sum(x – x_i^2))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Crear y entrenar el modelo SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1222d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241e04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae20190",
   "metadata": {},
   "source": [
    "### Actividad1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25acb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Size</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>4.39</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>4.21</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>4.09</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>5.85</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>4.70</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  Size   Class\n",
       "0      69  4.39  orange\n",
       "1      69  4.21  orange\n",
       "2      65  4.09  orange\n",
       "3      72  5.85   apple\n",
       "4      67  4.70  orange"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../Data/apples_and_oranges.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a139d",
   "metadata": {},
   "source": [
    "### Actividad 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c964f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "# Cargar el dataset Wine\n",
    "wine = datasets.load_wine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722028c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
